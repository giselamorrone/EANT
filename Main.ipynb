{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset que se va a utilizar es un dataset con información de tumores, tanto malignos como beningnos. La variable que se quiere predecir es *dignosis*, a partir de datos que fueron clasificados de imagenes de los tumores.\n",
    "\n",
    "Las variables fueron computadas de una imagen digitalizada con un aspirado de una aguja fina (FNA) de una masa del seno. Describen caracteristicas de los nucleos celulares presentes en la imagen. \n",
    "\n",
    "Informacion de las variables:\n",
    "\n",
    "1. ID \n",
    "2. Diagnosis (M = maligno, \n",
    "    B = benigno)\n",
    "3. (3-32) 10 valores computados para cada nucleo celular:\n",
    "    - radius -> distancia del centro hasta puntos en perimetros\n",
    "    - texture -> desviacion standar en scalas de grises de los valores\n",
    "    - perimeter\n",
    "    - area\n",
    "    - smoothness -> variación local en longitudes de radio\n",
    "    - compactness -> (perimeter^2 / area - 1.0)\n",
    "    - concavity -> Gravedad de las porciones cóncavas del contorno\n",
    "    - concave points -> Número de porciones cóncavas del contorno\n",
    "    - symmetry\n",
    "    - fractal dimension -> aproximación a la costa\n",
    "    \n",
    "Cada una de las variables de la 3 a la 32 estan computadas 3 veces, teniendo el valor MEAN (valor promedio de las mediciones para la imagen), SE (error estadar), WORST (peor valor). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligio este dataset para el analisis, dado que me resulto interesante poder hacer un analisis sobre un tema de salud, y poder ver si es realmente posible a partir de imagenes digitalizadas llegar a la conclusion de si una persona tiene o no cancer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorar Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#importar archivo de funciones de usuario\n",
    "import import_ipynb\n",
    "import Functions as fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar con el analisis de variables, se convierte la variable objetivo en 1 y 0 para un analisis mas facil:\n",
    "- M = 1\n",
    "- B = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division Train - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['diagnosis','id'], axis=1)\n",
    "\n",
    "y = df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=382)\n",
    "\n",
    "print('Train = ' , X_train.shape[0],'\\nTest = ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero BKP de los dataset de training y test\n",
    "X_train_bkp = X_train.copy()\n",
    "X_test_bkp = X_test.copy()\n",
    "y_train_bkp = y_train.copy()\n",
    "y_test_bkp = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeo cuantos casos de Tumores Benignos y Malignos quedaron por dataset\n",
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "sb.countplot(y_train,label=\"Cant\",ax=ax[0])\n",
    "ax[0].set_title('Cantidad de Tumores Beningnos = 0  y Malignos = 1 en Train')\n",
    "ax[0].set_yticks(range(0,300,25))\n",
    "sb.countplot(y_test,label=\"Cant\",ax=ax[1])\n",
    "ax[1].set_title('Cantidad de Tumores Beningnos = 0  y Malignos = 1 en Test')\n",
    "ax[1].set_yticks(range(0,300,25))\n",
    "B_train, M_train = y_train.value_counts()\n",
    "B_test, M_test = y_test.value_counts()\n",
    "print('En Train hay {} observaciones de tumores Benignos y {} observaciones  de tumores Malignos.\\nEn Test \\\n",
    "hay {} observaciones de tumores Benignos y {} observaciones de tumores Malignos.'.format(B_train,M_train,B_test,M_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco Nulos\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de Variables - CORRELACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables se dividen en 3 grupos:\n",
    "- 0-10 mean\n",
    "- 10-20 se\n",
    "- 20-31 worst\n",
    "\n",
    "Por lo que se va a analizar la correlacion de variables entre las variables dentro de esos 3 grupos.\n",
    "\n",
    "Al haber correlacion entre las variables, se puede eliminar alguna de ellas y conservar la otra. Para esto se va a analizar como se calculan estas variables, los outliers que puedan tener y los graficos de las mismas para ver sus correlaciones.\n",
    "\n",
    "Tomando como referencia para analisis los valores por arriba de 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *MEAN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(14, 14))\n",
    "mask = np.zeros_like(X_train.iloc[:,0:10].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sb.axes_style(\"white\"):\n",
    "    ax = sb.heatmap(X_train.iloc[:,0:10].corr(),annot=True, mask=mask,  linewidths=.5, fmt= '.3f',\\\n",
    "                    square=True,cbar=False,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico se puede ver que:\n",
    "- `radius_mean` esta fuertemente correlacionada con `perimeter_mean` y `area_mean`\n",
    "- `perimeter_mean` esta correlacionada en menor medida con `concave points_mean`\n",
    "- `compactness_mean` esta correlacionada en gran medida con `concavity_mean`\n",
    "- `concavity_mean` esta correlacionada en gran medida con `concave points_mean`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radius_mean - perimeter_mean - area_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[X_train.radius_mean > X_train.radius_mean.quantile(0.9)]\n",
    "b = X_train[X_train.perimeter_mean > X_train.perimeter_mean.quantile(0.9)]\n",
    "c = X_train[X_train.area_mean > X_train.area_mean.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para radius_mean.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para perimeter_mean.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para area_mean.'.format(a.shape[0],b.shape[0],c.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a utilizar un **Pair Grid Plot** para graficar las 3 variables juntas para ver que tan correlacionadas estan. \n",
    "\n",
    "En la diagonal se puede observar el comportamiento de cada una de las variables, y como podemos ver los graficos de las 3 son muy similares (en otros rangos numericos, dado que no estan escaladas las variables).\n",
    "\n",
    "En la parte inferior se observa la densidad de la distribucion de la cobinacion de las variables que se cruzan en esa combinacion y en la parte superior se usa un scatter plot para mostrar la relacion entre ambas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = X_train.loc[:,['radius_mean','perimeter_mean','area_mean']]\n",
    "g = sb.PairGrid(sub_set, diag_sharey=False)\n",
    "g.map_lower(sb.kdeplot)\n",
    "g.map_upper(plt.scatter)\n",
    "g.map_diag(sb.kdeplot, lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado este analisis y sabiendo que los tumores tienen una forma similar a la circular, y el calculo del area y el perimetro se hace en base al radio, tiene sentido que las 3 variables esten correlacionadas. Dado que el radio tiene menos outliers, se van a eliminar el `perimetro` y el `area`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perimeter_mean - concave points_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = X_train[X_train.loc[:,'concave points_mean'] > X_train.loc[:,'concave points_mean'].quantile(0.9)]\n",
    "b = X_train[X_train.perimeter_mean > X_train.perimeter_mean.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para concave points_mean.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para perimeter_mean.'.format(a.shape[0],b.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso como las variables a analizar son 2 se va a generar un **JointPlot** para ver como estan correlacionadas.\n",
    "\n",
    "En el centro del grafico se puede observar la relacion entre las variables, y por fuera del grafico se ve el grafico de cada una de las variables.\n",
    "\n",
    "Estas dos variables tienen una correlacion bastante menor que el resto de las halladas (0.85), de todas maneras, como en el paso anterior ya se decidio que `perimeter_mean` iba a ser eliminada por su correlacion con `radius_mean` no es necesario hacer mas en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(X_train.loc[:,'concave points_mean'], X_train.loc[:,'perimeter_mean'], kind=\"reg\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compactness_mean - concavity_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca pasa lo mismo que en el caso anterior, como son dos variables para ver la correlacion hago un **JointPlot**. De este puedo observar que las variables son bastante parecidas, pero tienen alguna diferencia. \n",
    "\n",
    "En particular se puede observaar que `compactness_mean` tiene mayor distibucion de valores que `concavity_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(X_train.loc[:,'compactness_mean'], X_train.loc[:,'concavity_mean'], kind=\"reg\", color=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[X_train.compactness_mean > X_train.compactness_mean.quantile(0.9)]\n",
    "b = X_train[X_train.concavity_mean > X_train.concavity_mean.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para compactness_mean.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para concavity_mean.'.format(a.shape[0],b.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso ambas variables tienen la misma cantidad de outliers, por lo que voy a eliminar `concavity_mean` dado que es la que tienen menos varianza en sus valores. Como de todas formas, `concavity_mean` tiene una correlacion mas con otra variable, antes de eliminar voy a ver que surje de ese analisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concavity_mean - concave points_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(X_train.loc[:,'concave points_mean'], X_train.loc[:,'concavity_mean'], kind=\"reg\", color=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del grafico anterior se puede observar que las variables estan fuertemente correlacionadas, y ademas se puede observar que tienen graficos muy similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = X_train[X_train.loc[:,'concave points_mean'] > X_train.loc[:,'concave points_mean'].quantile(0.9)]\n",
    "b = X_train[X_train.concavity_mean > X_train.concavity_mean.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para concave points_mean.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para concavity_mean.'.format(a.shape[0],b.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del grafico superior se puede observar que `concave points_mean` tiene outliers en un rango mayor de valores, por eso se elimina esa variable.\n",
    "Al eliminar esta, del analisis anterior, se va a eliminar `compactness_mean`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Por lo tanto se van a eliminar:\n",
    "    - perimeter_mean\n",
    "    - area_mean\n",
    "    - concave points_mean\n",
    "    - compactness_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *SE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(14, 14))\n",
    "mask = np.zeros_like(X_train.iloc[:,10:20].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sb.axes_style(\"white\"):\n",
    "    ax = sb.heatmap(X_train.iloc[:,10:20].corr(),annot=True, mask=mask,vmax=1,  linewidths=.5, fmt= '.3f',\\\n",
    "                     square=True,cbar=False,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico se puede ver que:\n",
    "- `radius_se` esta fuertemente correlacionada con `perimeter_se` y `area_se`\n",
    "- `compactness_se` esta correlacionada en gran medida con `concavity_se`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radius_se - perimeter_se - area_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el caso del conjunto _MEAN_ se podria asumir que como el perimetro y el area son un calculo del radio se podrian eliminar `perimeter_se` y `area_se`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = X_train.loc[:,['radius_se','perimeter_se','area_se']]\n",
    "g = sb.PairGrid(sub_set, diag_sharey=False)\n",
    "g.map_lower(sb.kdeplot)\n",
    "g.map_upper(plt.scatter)\n",
    "g.map_diag(sb.kdeplot, lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del grafico se puede observar que las variables estan fuertemente correlacionadas, y sus graficos son bastante similares, por lo tanto al igual que para el conjunto de variables _MEAN_ se va a eliminar `perimeter_se` y `area_se`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compactness_se - concavity_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(X_train.loc[:,'compactness_se'], X_train.loc[:,'concavity_se'], kind=\"reg\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[X_train.compactness_se > X_train.compactness_se.quantile(0.9)]\n",
    "b = X_train[X_train.concavity_se > X_train.concavity_se.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para compactness_se.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para concavity_se.'.format(a.shape[0],b.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del grafico superior se puede ver que las variables estan correlacionadas, y tienen graficos bastantes similares. Como ambas tienen las mismas cantidad de outliers, voy a eliminar `compactness_se` dado que del grafico de `compactness_se` se puede observar que esta tienen menos varianza en sus valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Por lo tanto se van a eliminar:\n",
    "    - perimeter_se\n",
    "    - area_se\n",
    "    - compactness_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *WORST*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(14, 14))\n",
    "mask = np.zeros_like(X_train.iloc[:,20:31].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sb.axes_style(\"white\"):\n",
    "    ax = sb.heatmap(X_train.iloc[:,20:31].corr(),annot=True, mask=mask,vmax=1,  linewidths=.5, fmt= '.3f',\\\n",
    "                     square=True,cbar=False,cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico se puede ver que:\n",
    "- `radius_worst` esta fuertemente correlacionada con `perimeter_worst` y `area_worst`\n",
    "- `compactness_worst` esta correlacionada en gran medida con `concavity_worst`\n",
    "- `concavity_worst` esta correlacionada con `concave points_worst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radius_se - perimeter_se - area_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = X_train.loc[:,['radius_worst','perimeter_worst','area_worst']]\n",
    "g = sb.PairGrid(sub_set, diag_sharey=False)\n",
    "g.map_lower(sb.kdeplot)\n",
    "g.map_upper(plt.scatter)\n",
    "g.map_diag(sb.kdeplot, lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que el conjunto de variables _MEAN_ y _SE_ se puede observar que esta fuertemente correlacionadas y que tienen graficos muy similares. Por lo tanto se va a tomar la misma logica que para los dos grupos anteriores eliminando `perimeter_worst` y `area_worst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compactness_worst - concavity_worst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(X_train.loc[:,'compactness_worst'], X_train.loc[:,'concavity_worst'], kind=\"reg\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[X_train.compactness_worst > X_train.compactness_worst.quantile(0.9)]\n",
    "b = X_train[X_train.concavity_worst > X_train.concavity_worst.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para compactness_worst.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para concavity_worst.'.format(a.shape[0],b.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 10))\n",
    "X_train[['compactness_worst','concavity_worst']].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del grafico de arriba se puede ver que las variables estan fuertemente correlacionadas, y tienen graficos bastante similares. Del grafico **BOXPLOT** se puede ver que `compactness_worst` tiene los outliers mas distribuidos por lo tanto se la va a eliminar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concavity_worst - concave points_worst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.jointplot(X_train.loc[:,'concave points_worst'], X_train.loc[:,'concavity_worst'], kind=\"reg\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[X_train.loc[:,'concave points_worst'] > X_train.loc[:,'concave points_worst'].quantile(0.9)]\n",
    "b = X_train[X_train.concavity_worst > X_train.concavity_worst.quantile(0.9)]\n",
    "print('Hay {} observaciones por encima del quantile 90 para concave points_worst.\\n\\\n",
    "Hay {} observaciones por encima del quantile 90 para concavity_worst.'.format(a.shape[0],b.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ambas tienen la misma cantidad de outliers se va a eliminar `concave points_worst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Por lo tanto se van a eliminar:\n",
    "    - perimeter_worst\n",
    "    - area_worst\n",
    "    - compactness_worst\n",
    "    - concave points_worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminacion de las variables seleccionadas del analisis por grupos _MEAN_ - _SE_ - _WORST_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['perimeter_mean' ,'area_mean','concave points_mean' ,'compactness_mean',\\\n",
    "              'perimeter_se' ,'area_se', 'compactness_se', \\\n",
    "              'perimeter_worst', 'area_worst', 'compactness_worst', 'concave points_worst']\\\n",
    "             , axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Con el analisis de correlación por grupos se quitaron {} variables.\"\\\n",
    "      .format(X_train_bkp.shape[1] - X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo en una variable la cantidad de variables que tiene el dataframe despues del analisis de correlacion \n",
    "var_dCor = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de Variables - Analisis de clasificacion de cada variables\n",
    "\n",
    "Se va a generar un grafico **Violinpoint** para ver como cada una de las variables ayuda a clasificar la variable objetivo.\n",
    "\n",
    "Para poder graficar todas las variables en el mismo grafico se las va a estandarizar, y para poder luego realizar el grafico se tiene que juntar las **variables (X_train)** con la **variable objetico (y_train)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizacion\n",
    "X_train_stand = (X_train - X_train.mean()) / (X_train.std())  \n",
    "X = pd.concat([X_train_stand,y_train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_melt = pd.melt(X,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Violinpoint\n",
    "X_melt = pd.melt(X,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(20,10))\n",
    "sb.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=X_melt,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico anterior se puede ver:\n",
    "- smoothness_mean\n",
    "- symmetry_mean\n",
    "- fractal_dimension_mean\n",
    "- texture_se\n",
    "- smoothness_se\n",
    "- symmetry_se\n",
    "- fractal_dimension_se\n",
    "- symmetry_worst\n",
    "- fractal_dimension_worst\n",
    "\n",
    "No tienen una gran diferencia entre B y M, por lo tanto se va a proceder a eliminarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['smoothness_mean','symmetry_mean','fractal_dimension_mean','texture_se','smoothness_se',\\\n",
    "             'symmetry_se','fractal_dimension_se','symmetry_worst','fractal_dimension_worst'\\\n",
    "             ], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Con el analisis de violinpoint se quitaron {} variables.\".format(var_dCor - X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el analisis de correlación por grupos se quitaron 11 variables. Y con el analisis de clasificacion se eliminaron 9 variables mas, dejando el dataframe con 10 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de Variables - Automatico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion Recursivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 20)\n",
    "\n",
    "selector = RFE(clf, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train_bkp, y_train_bkp)\n",
    "mask = selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XR = X_train_bkp.iloc[:,np.append(np.array([True,True]),mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Con la seleccion Recursiva el dataframe queda con {}.\".format(XR.shape[1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Poca Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(0.01))\n",
    "X_thr = sel.fit_transform(X_train_bkp)\n",
    "mask = sel.fit(X_train_bkp).get_support()\n",
    "print(\"Se quitaron {} columnas a partir de remover las de baja varianza.\".format(X_train_bkp.shape[1] - X_thr.shape[1]))\n",
    "\n",
    "XV = X_train_bkp.iloc[:,np.append(np.array([True,True]),mask)]\n",
    "print(\"Con la seleccion de Poca Varianza el dataframe queda con {}.\".format(XV.shape[1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe X_train con analisis a mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 10))\n",
    "X_train[['radius_mean','texture_mean','radius_worst','texture_worst']].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 10))\n",
    "X_train[['concavity_mean','concavity_se',\\\n",
    "         'concave points_se','smoothness_worst']].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 10))\n",
    "X_train[['radius_se','concavity_worst']].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizo que cantidad de observaciones hay con outliers por arriba del quantile .9 para cada uno de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[X_train.radius_mean > X_train.radius_mean.quantile(0.90)]\n",
    "b = X_train[X_train.texture_mean > X_train.texture_mean.quantile(0.90)]\n",
    "c = X_train[X_train.radius_worst > X_train.radius_worst.quantile(0.90)]\n",
    "d = X_train[X_train.texture_worst > X_train.texture_worst.quantile(0.90)]\n",
    "e = X_train[X_train.concavity_mean > X_train.concavity_mean.quantile(0.90)]\n",
    "f = X_train[X_train.concavity_se > X_train.concavity_se.quantile(0.90)]\n",
    "g = X_train[X_train.loc[:,'concave points_se'] > X_train.loc[:,'concave points_se'].quantile(0.90)]\n",
    "h = X_train[X_train.smoothness_worst > X_train.smoothness_worst.quantile(0.90)]\n",
    "i = X_train[X_train.radius_se > X_train.radius_se.quantile(0.90)]\n",
    "j = X_train[X_train.concavity_worst > X_train.concavity_worst.quantile(0.90)]\n",
    "\n",
    "\n",
    "print('radius_mean: ' , a.shape[0],\\\n",
    "      '\\ntexture_mean: ' , b.shape[0],\\\n",
    "      '\\nradius_worst:', c.shape[0],\\\n",
    "      '\\ntexture_worst: ',d.shape[0],\\\n",
    "      '\\nconcavity_mean:',e.shape[0],\\\n",
    "      '\\nconcavity_se:',f.shape[0],\\\n",
    "      '\\nconcave points_se: ',g.shape[0],\\\n",
    "      '\\nsmoothness_worst:',h.shape[0],\\\n",
    "      '\\nradius_se:',i.shape[0],\\\n",
    "      '\\nconcavity_worst:',j.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen al menos 45 o 46 observaciones con outliers por variable, las cuales pueden o no coincidir entre si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion - Outliers\n",
    "Dados estos numeros se toma la decision de a efectos de poder probar el modelo se va a :\n",
    "- Generar un dataframe eliminando el 2% de los outliers `X2`\n",
    "- Generar un dataframe eliminando el 5% de los outliers `X5`\n",
    "- Generar un dataframe sin eliminar outliers `XS`\n",
    "- Generar un dataframe en el cual a los valores por arriba del quantile .9 se les imputa la media `XM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([y_train,X_train], axis=1)\n",
    "X2 = X.copy()\n",
    "X5 = X.copy()\n",
    "XS = X.copy()\n",
    "XM = X.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino 2% de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = fun.eliminar_outliers(X2,X,X2.columns, 0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino 5% de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = fun.eliminar_outliers(X5,X,X5.columns,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputo la Media a los Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XM = fun.eliminar_outliers(XM,X,XM.columns,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe XR con RFE\n",
    "- XR2 eliminacion del 2%\n",
    "- XR5 eliminacion del 5%\n",
    "- XRM imputacion de la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XR2 = pd.concat([y_train,XR], axis=1)\n",
    "XR5 = pd.concat([y_train,XR], axis=1)\n",
    "XRM = pd.concat([y_train,XR], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino 2% de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XR2 = fun.eliminar_outliers(XR2,XR, XR.columns,0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino el 5% de los outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifico los outliers por variable al 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XR5 = fun.eliminar_outliers(XR5,XR, XR.columns,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputo la Media a los Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XRM = fun.eliminar_outliers(XRM,XR, XR.columns,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe XV con Variance Threshold\n",
    "- XV2 eliminacion del 2%\n",
    "- XV5 eliminacion del 5%\n",
    "- XVM imputacion de la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XV2 = pd.concat([y_train,XV], axis=1)\n",
    "XV5 = pd.concat([y_train,XV], axis=1)\n",
    "XVM = pd.concat([y_train,XV], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino el 2% de los outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XV2 = fun.eliminar_outliers(XV2,XV, XV.columns,0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino el 5% de los outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XV5 = fun.eliminar_outliers(XV5,XV, XV.columns,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputo la Media a los Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifico cantidad de outliers por variable al 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVM = fun.eliminar_outliers(XVM,XV, XV.columns,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la prueba de modelos se van a utilizar los siguientes dataframe:\n",
    "- X_train_bkp que es el dataframe original, sin eliminar ninguna variable ni outliers\n",
    "- X2 es el resultado del analisis a mano de correlacion, y violinpoint, y eliminacion del 2% de outliers\n",
    "- X5 es el resultado del analisis a mano de correlacion, y violinpoint, y eliminacion del 5% de outliers\n",
    "- XM es el resultado del analisis a mano de correlacion, y violinpoint, e imputacion de outliers por la media\n",
    "- XS es el resultado del analisis a mano de correlacion, y violinpoint, pero sin eliminacion de outliers\n",
    "- XR es el resultado del modelo RFE sin eliminacion de outliers\n",
    "- XR2 es el resultado del modelo RFE y la eliminacion del 2% de los outliers\n",
    "- XR5 es el resultado del modelo RFE y la eliminacion del 5% de los outliers\n",
    "- XRM es el resultado del modelo RFE e imputacion de outliers por la media\n",
    "- XV es el resultado del modelo de Varianza Threshold\n",
    "- XV2 es el resultado del modelo de Varianza Threshold y la eliminacion del 2% de los outliers\n",
    "- XV5 es el resultado del modelo de Varianza Threshold y la eliminacion del 5% de los outliers\n",
    "- XVM es el resultado del modelo de Varianza Threshold e imputacion de los outliers por la media\n",
    "\n",
    "`X_test` e `y_test` son los dataframe para test, que deben ser ajustados para cada grupo de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los dataframe creados tiene la variable objetivo como parte de sus variables, por lo tanto se la va a separar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "#X_train_bkp\n",
    "predictions = fun.models(X_train_bkp,y_train_bkp,X_test,y_test,'X_train_bkp')\n",
    "\n",
    "#X2\n",
    "y2,X2 = fun.split(X2)\n",
    "predictions = predictions.append(fun.models(X2,y2,X_test[X2.columns],y_test,'X2'))\n",
    "\n",
    "\n",
    "\n",
    "#X5\n",
    "y5,X5 = fun.split(X5)\n",
    "\n",
    "#XM\n",
    "yM,XM = fun.split(XM)\n",
    "\n",
    "#XS\n",
    "yS,XS = fun.split(XS)\n",
    "\n",
    "#XR2\n",
    "yR2,XR2 = fun.split(XR2)\n",
    "\n",
    "#XR5\n",
    "yR5,XR5 = fun.split(XR5)\n",
    "\n",
    "#XRM\n",
    "yRM ,XRM = fun.split(XRM)\n",
    "\n",
    "#XV2\n",
    "yV2 , XV2 = fun.split(XV2)\n",
    "\n",
    "#XV5\n",
    "yV5 ,XV5 = fun.split(XV5)\n",
    "\n",
    "#XVM\n",
    "yVM ,XVM = fun.split(XVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
