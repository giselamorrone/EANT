{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"pull-right\"><img src=\"https://eant.tech/imagenes/logo.png\"/></div/>\n",
    "<h1> <font color=#736AFF> Funciones generadas por usuario </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=#2B65EC> Funciones para eliminar outliers </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_outliers (dataframe,X, columns,porc=0):\n",
    "    #dataframe = dataframe del cual se van a eliminar outliers o imputar la media\n",
    "    #X = dataframe original, del cual se toma el quantile\n",
    "    #porc = porcentaje que se va a considerar, si es 0 se imputa la media\n",
    "    #columns = columnas dentro del dataframe\n",
    "    \n",
    "    for i in range(0,len(columns)):\n",
    "        if porc == 0:\n",
    "        #Imputar la media\n",
    "            dataframe[dataframe.loc[:,columns[i]]  > X.loc[:,columns[i]].quantile(0.9)] =\\\n",
    "                dataframe.loc[:,columns[i]].mean()\n",
    "        else:\n",
    "        #eliminar PORCENTAJE del dataframe\n",
    "            dataframe =  dataframe[dataframe.loc[:,columns[i]]< X.loc[:,columns[i]].quantile(porc)]\n",
    "        \n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=#2B65EC> Funciones para separar el dataframe con variable objetivo y variables independientes </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataframes):\n",
    "    import pandas as pd\n",
    "    \n",
    "    obj = pd.DataFrame(columns=['y_train'])\n",
    "    IND = pd.DataFrame(columns=['X_train','Name'])\n",
    "    \n",
    "    for i in range(0,len(dataframes)):\n",
    "        obj1 = dataframes.iloc[i].Dataframe.diagnosis\n",
    "        IND1 = dataframes.iloc[i].Dataframe.drop(['diagnosis'], axis=1)\n",
    "        name1 = dataframes.iloc[i].Name\n",
    "        \n",
    "        obj = obj.append({'y_train': obj1 },ignore_index=True)\n",
    "        IND =IND.append({'X_train':IND1,'Name': name1},ignore_index=True)\n",
    "        \n",
    "    \n",
    "    return obj,IND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=#2B65EC> Funciones para aplicar modelos </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train,y_train,X_test,y_test):\n",
    "    #X_train = dataframe que tiene todos los generados (variables independientes training), y el nombre del mismo\n",
    "    #y_train = dataframe que tiene todos los generados ( variable objetivo training)\n",
    "    #X_test = variables independientes testing\n",
    "    #y_test =variable objetivo testing\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.linear_model import LinearRegression, SGDClassifier , RidgeClassifierCV,\\\n",
    "        LassoLarsCV, BayesianRidge, Lasso\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    clf = pd.DataFrame(columns=['Model','Name'])\n",
    "    predictions = pd.DataFrame(columns=['Model','Dataframe','Acuraccy'])\n",
    "     \n",
    "    ##TREE - decision trees learn from data to approximate \n",
    "    #a sine curve with a set of if-then-else decision rules\n",
    "    #DecisionTreeRegressor \n",
    "    clf =clf.append({'Model':DecisionTreeRegressor(random_state=0, max_depth=4), \\\n",
    "                 'Name': 'DecisionTreeRegressor'},ignore_index=True)\n",
    "    ##LINEAR MODEL\n",
    "    #Ordinary least squares Linear Regression.\n",
    "    clf = clf.append({'Model':LinearRegression(), 'Name': 'LinearRegression'},ignore_index=True)\n",
    "    #Linear classifiers (SVM, logistic regression, a.o.) with SGD training.\n",
    "    clf = clf.append({'Model': SGDClassifier(max_iter=300), 'Name': 'SGDClassifier'},ignore_index=True)\n",
    "    #Ridge classifier with built-in cross-validation.\n",
    "    clf = clf.append({'Model': RidgeClassifierCV(), 'Name': 'RidgeClassifierCV'},ignore_index=True)\n",
    "    #Bayesian ridge regression\n",
    "    clf = clf.append({'Model': BayesianRidge(), 'Name': 'BayesianRidge'},ignore_index=True)\n",
    "    #Linear Model trained with L1 prior as regularizer (aka the Lasso)\n",
    "    clf = clf.append({'Model': Lasso(alpha=0.1), 'Name': 'Lasso'},ignore_index=True)\n",
    "    #Cross-validated Lasso, using the LARS algorithm.\n",
    "    clf = clf.append({'Model': LassoLarsCV(cv=5), 'Name': 'LassoLarsCV'},ignore_index=True)\n",
    "    ##GaussianNB\n",
    "    #Gaussian Naive Bayes algorithm for classification.\n",
    "    clf = clf.append({'Model': GaussianNB(), 'Name': 'GaussianNB'},ignore_index=True)\n",
    "    ##SVM\n",
    "    #SVC\n",
    "    clf = clf.append({'Model': SVC(), 'Name': 'SVC'},ignore_index=True)\n",
    "    ##NEIGHBORS\n",
    "    #KNeighborsRegressor\n",
    "    clf = clf.append({'Model': KNeighborsRegressor(n_neighbors=23), 'Name':'KNeighborsRegressor'},ignore_index=True)\n",
    "    ##CLUSTER\n",
    "    #Algorithm clusters data by trying to separate samples in n groups of equal variance\n",
    "    clf = clf.append({'Model': KMeans(n_clusters=2, random_state=0), 'Name':'KMeans'},ignore_index=True)\n",
    "    ##ensemble\n",
    "    ##RandomForestRegressor - each tree in the ensemble is built from a sample drawn with replacement\n",
    "    clf = clf.append({'Model': RandomForestRegressor(n_jobs=-1, n_estimators=50, max_depth=5),\\\n",
    "                      'Name':'RandomForestRegressor'},ignore_index=True)\n",
    "    \n",
    " \n",
    "    for i in range(0,len(clf)):\n",
    "        for j in range(len(X_train)):\n",
    "            try:\n",
    "                model = clf.iloc[i].Model.fit(X_train.iloc[j].X_train, y_train.iloc[j].y_train)\n",
    "                y_pred = model.predict(X_test[X_train.iloc[j].X_train.columns])\n",
    "                Acuraccy = np.sqrt(accuracy_score(y_test, y_pred))\n",
    "                predictions = predictions.append({'Model': clf.iloc[i].Name ,\\\n",
    "                                                  'Dataframe': X_train.iloc[j].Name ,'Acuraccy':Acuraccy},\\\n",
    "                                     ignore_index=True) \n",
    "            except: \n",
    "                continue\n",
    "                \n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
